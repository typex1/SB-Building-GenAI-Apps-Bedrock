{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fded102b",
   "metadata": {},
   "source": [
    "# Text summarization with small files with Anthropic Claude\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8b2cf",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this example, you are going to ingest a small amount of data (String data) directly into Amazon Bedrock API (using Anthropic Claude model) and give it an instruction to summarize the respective text. You will learn how to do that with both the Claude 2.x and the latest Claude 3.x models\n",
    "\n",
    "### Architecture\n",
    "\n",
    "![](./images/41-text-simple-1.png)\n",
    "\n",
    "In this architecture:\n",
    "\n",
    "1. A small piece of text (or small file) is loaded\n",
    "1. A foundation model processes the input data\n",
    "1. Model returns a response with the summary of the ingested text\n",
    "\n",
    "### Use case\n",
    "\n",
    "This approach can be used to summarize call transcripts, meetings transcripts, books, articles, blog posts, and other relevant content.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "This approach can be used when the input text or file fits within the model context length. In `Lab 2b` we will explore an approach to address the challenge when users have large document(s) that exceed the token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66edf151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342796d0",
   "metadata": {},
   "source": [
    "## Summarizing a short text with boto3\n",
    " \n",
    "To learn detail of API request to Amazon Bedrock, this notebook introduces how to create API request and send the request via Boto3 rather than relying on langchain, which gives simpler API by wrapping Boto3 operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4d9ee",
   "metadata": {},
   "source": [
    "### Request Syntax of InvokeModel in Boto3\n",
    "\n",
    "\n",
    "We use `InvokeModel` API for sending request to a foundation model. Here is an example of API request for sending text to Anthropic Claude. Inference parameters in `textGenerationConfig` depends on the model that you are about to use. Inference paramerters of Anthropic Claude are:\n",
    "\n",
    "- **temperature** tunes the degree of randomness in generation. Lower temperatures mean less random generations.\n",
    "- **top_p** less than one keeps only the smallest set of most probable tokens with probabilities that add up to top_p or higher for generation.\n",
    "- **top_k** can be used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.\n",
    "- **max_tokens_to_sample** is maximum number of tokens to generate. Responses are not guaranteed to fill up to the maximum desired length.\n",
    "- **stop_sequences** are sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n",
    "\n",
    "```python\n",
    "response = bedrock.invoke_model(body=\n",
    "                                {\"prompt\":\"this is where you place your input text\",\n",
    "                                 \"max_tokens_to_sample\":4096,\n",
    "                                 \"temperature\":0.5,\n",
    "                                 \"top_k\":250,\n",
    "                                 \"top_p\":0.5,\n",
    "                                 \"stop_sequences\":[]\n",
    "                                },\n",
    "                                modelId=\"anthropic.claude-v2\", \n",
    "                                accept=accept, \n",
    "                                contentType=contentType)\n",
    "\n",
    "```\n",
    "\n",
    "### Writing prompt with text to be summarized\n",
    "\n",
    "In this notebook, you can use any short text whose tokens are less than the maximum token of a foundation model. As an exmple of short text, let's take one paragraph of an [AWS blog post](https://aws.amazon.com/jp/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/) about announcement of Amazon Bedrock.\n",
    "\n",
    "The prompt starts with an instruction `Please provide a summary of the following text.`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece0c069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Human: Please provide a summary of the following text.\n",
    "<text>\n",
    "AWS took all of that feedback from customers, and today we are excited to announce Amazon Bedrock, \\\n",
    "a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. \\\n",
    "Bedrock is the easiest way for customers to build and scale generative AI-based applications using FMs, \\\n",
    "democratizing access for all builders. Bedrock will offer the ability to access a range of powerful FMs \\\n",
    "for text and images—including Amazons Titan FMs, which consist of two new LLMs we’re also announcing \\\n",
    "today—through a scalable, reliable, and secure AWS managed service. With Bedrock’s serverless experience, \\\n",
    "customers can easily find the right model for what they’re trying to get done, get started quickly, privately \\\n",
    "customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS \\\n",
    "tools and capabilities they are familiar with, without having to manage any infrastructure (including integrations \\\n",
    "with Amazon SageMaker ML features like Experiments to test different models and Pipelines to manage their FMs at scale).\n",
    "</text>\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efddbb0",
   "metadata": {},
   "source": [
    "## Creating request body with prompt and inference parameters \n",
    "\n",
    "Following the request syntax of `invoke_model`, you create request body with the above prompt and inference parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d191eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt,\n",
    "                 \"max_tokens_to_sample\":4096,\n",
    "                 \"temperature\":0.5,\n",
    "                 \"top_k\":250,\n",
    "                 \"top_p\":0.5,\n",
    "                 \"stop_sequences\":[]\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f3326",
   "metadata": {},
   "source": [
    "## Invoke foundation model via Boto3\n",
    "\n",
    "Here sends the API request to Amazon Bedrock with specifying request parameters `modelId`, `accept`, and `contentType`. Following the prompt, the foundation model in Amazon Bedrock summarizes the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f400d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the key points from the text:\n",
      "\n",
      "- AWS announced Amazon Bedrock, a new service that provides API access to large language models (LLMs) from AI21 Labs, Anthropic, Stability AI, and Amazon. \n",
      "\n",
      "- Bedrock aims to make generative AI more accessible to developers by allowing them to easily integrate and deploy powerful text and image generation models into their applications.\n",
      "\n",
      "- Bedrock offers serverless access to models including two new Titan LLMs from Amazon. \n",
      "\n",
      "- Key benefits of Bedrock highlighted are scalability, reliability, security, easy integration with AWS services, and not having to manage infrastructure.\n",
      "\n",
      "- Developers can customize models with their own data, test different models, and manage models at scale.\n"
     ]
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-v2' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c84a0",
   "metadata": {},
   "source": [
    "In the above the Bedrock service generates the entire summary for the given prompt in a single output, this can be slow if the output contains large amount of tokens. \n",
    "\n",
    "Below we explore the option how we can use Bedrock to stream the output such that the user could start consuming it as it is being generated by the model. For this Bedrock supports `invoke_model_with_response_stream` API providing `ResponseStream` that streams the output in form of chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3aa446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': {'bytes': b'{\"completion\":\" Here\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" is\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" a\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" summary\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" of\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" the\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" key\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" points\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" from\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" the\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" text\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\":\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AWS\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" announced\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Amazon\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" a\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" new\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" service\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" that\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" provides\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" API\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" access\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" large\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" language\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" (\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"LL\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"Ms\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\")\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" from\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AI\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"21\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Labs\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" An\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"throp\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ic\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" St\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AI\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Amazon\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" \",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" aims\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" make\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" gener\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ative\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AI\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" more\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" accessible\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" developers\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" by\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" allowing\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" them\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" easily\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" integrate\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" deploy\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" powerful\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" text\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" image\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" generation\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" into\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" their\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" applications\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" offers\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" server\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"less\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" access\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" including\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" two\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" new\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Titan\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" LL\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"Ms\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" from\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Amazon\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" \",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\\\\n\\\\n-\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Key\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" benefits\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" of\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" Bed\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"rock\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" include\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" scal\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"ability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" reliability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" security\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" easy\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" integration\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" with\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" AWS\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" services\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\",\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" and\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" the\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" ability\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" to\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" customize\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" models\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" with\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" your\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" own\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" data\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" without\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" managing\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\" infrastructure\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\".\",\"stop_reason\":null,\"stop\":null}'}},\n",
       " {'chunk': {'bytes': b'{\"completion\":\"\",\"stop_reason\":\"stop_sequence\",\"stop\":\"\\\\n\\\\nHuman:\",\"amazon-bedrock-invocationMetrics\":{\"inputTokenCount\":249,\"outputTokenCount\":145,\"invocationLatency\":5086,\"firstByteLatency\":1180}}'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-v2'\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = list(stream)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c1b3b",
   "metadata": {},
   "source": [
    "Instead of generating the entire output, Bedrock sends smaller chunks from the model. This can be displayed in a consumable manner as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ab3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0148858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Here is a summary of the key points from the text:\n",
       "\n",
       "- AWS announced Amazon Bedrock, a new service that provides API access to large language models (LLMs) from AI21 Labs, Anthropic, Stability AI, and Amazon. \n",
       "\n",
       "- Bedrock aims to make generative AI more accessible to developers by allowing them to easily integrate and deploy powerful text and image generation models into their applications.\n",
       "\n",
       "- Bedrock offers serverless access to models including two new Titan LLMs from Amazon. \n",
       "\n",
       "- Key benefits of Bedrock highlighted are scalability, reliability, security, easy integration with AWS services, and not having to manage infrastructure.\n",
       "\n",
       "- Developers can customize models with their own data, test different models, and manage models at scale."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-v2'\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['completion']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1eb962",
   "metadata": {},
   "source": [
    "# Using Claude 3 Messages API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec39c3d",
   "metadata": {},
   "source": [
    "The Claude 3.x models use the messages API. So you will construct your input using that. Here's an example of how to summarize the same text with the Claude 3 Sonnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ad827e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt}]}]\n",
    "\n",
    "body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 512,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 1\n",
    "        }  \n",
    "    )  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ceb2227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the provided text:\n",
      "\n",
      "AWS has announced a new service called Amazon Bedrock that provides access to foundation models (FMs) from AI companies like AI21 Labs, Anthropic, Stability AI, and Amazon itself via an API. Bedrock aims to democratize access to powerful generative AI models for text and images, including Amazon's own new Titan large language models (LLMs) that are also being launched. \n",
      "\n",
      "Bedrock offers a serverless experience that allows customers to easily find the right model for their needs, get started quickly, customize models with their own data privately, and integrate/deploy the models into applications using familiar AWS tools and services like SageMaker. This eliminates the need for customers to manage infrastructure themselves. Key features include the ability to test different models using SageMaker Experiments and manage models at scale with SageMaker Pipelines.\n",
      "\n",
      "Overall, Bedrock is positioned as the easiest way for AWS customers to build and scale generative AI applications using foundation models from multiple providers through a scalable, reliable, and secure managed service.\n"
     ]
    }
   ],
   "source": [
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_client.invoke_model(body=body, modelId=modelId)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "#print(response_body)\n",
    "output_list = response_body.get(\"content\", [])\n",
    "for output in output_list:\n",
    "    print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc64b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': {'bytes': b'{\"type\":\"message_start\",\"message\":{\"id\":\"msg_01W56NAHgwXzYhGm9j44hCSw\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[],\"model\":\"claude-3-sonnet-28k-20240229\",\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":263,\"output_tokens\":1}}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_start\",\"index\":0,\"content_block\":{\"type\":\"text\",\"text\":\"\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Here\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" is\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" summary\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" of\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" provided\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" text\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\":\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\\\n\\\\nAWS\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" has\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" announced\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" new\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" service\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" called\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" that\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" provides\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" access\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" foundation\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" (\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"F\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Ms\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\")\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" from\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" companies\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" like\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"21\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" \"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Labs\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Anthrop\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ic\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Stability\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" itself\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" via\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" an\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" API\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" aims\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" democrat\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ize\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" access\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" powerful\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" gener\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ative\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" text\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" images\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" including\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\'s\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" own\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" new\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Titan\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" F\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Ms\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" consisting\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" of\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" two\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" large\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" language\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" (\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"L\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"L\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"Ms\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\").\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" \"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\\\n\\\\nBed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" offers\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" server\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"less\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" experience\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" that\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" allows\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" customers\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" easily\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" find\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" right\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" model\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" their\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" needs\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" get\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" started\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" quickly\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" customize\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" with\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" their\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" own\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" data\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" integrate\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" them\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" into\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" applications\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" using\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" familiar\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AWS\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" tools\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" capabilities\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" This\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" elimin\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ates\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" need\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" customers\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" manage\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" infrastructure\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" themselves\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Key\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" features\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" include\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" ability\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" test\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" different\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" using\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Amazon\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" S\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ag\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"eM\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"aker\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Experiments\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" manage\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" at\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" scale\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" with\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" S\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ag\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"eM\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"aker\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Pip\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"elines\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"\\\\n\\\\nOverall\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" Bed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"rock\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" is\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" designed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" make\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" it\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" easier\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" for\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" all\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" builders\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" to\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" develop\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" and\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" scale\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" gener\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"ative\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AI\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" applications\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" lever\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"aging\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" state\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"-\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"of\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"-\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"the\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"-\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\"art\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" foundation\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" models\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" from\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" multiple\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" providers\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" through\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" a\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" unified\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" managed\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" AWS\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\" service\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"text_delta\",\"text\":\".\"}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"content_block_stop\",\"index\":0}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"message_delta\",\"delta\":{\"stop_reason\":\"end_turn\",\"stop_sequence\":null},\"usage\":{\"output_tokens\":231}}'}},\n",
       " {'chunk': {'bytes': b'{\"type\":\"message_stop\",\"amazon-bedrock-invocationMetrics\":{\"inputTokenCount\":263,\"outputTokenCount\":231,\"invocationLatency\":4996,\"firstByteLatency\":599}}'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\", accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = list(stream)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2daed291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the given text:\n",
      "\n",
      "AWS has announced a new service called Amazon Bedrock, which provides access to foundation models (FMs) from various AI companies like AI21 Labs, Anthropic, Stability AI, and Amazon itself through an API. Bedrock aims to democratize access to powerful generative AI models for text and images, including Amazon's own Titan FMs, which consist of two new large language models (LLMs) announced today.\n",
      "\n",
      "Bedrock offers a serverless experience, allowing customers to easily find the right model for their needs, get started quickly, privately customize FMs with their own data, and seamlessly integrate and deploy them into their applications using familiar AWS tools and capabilities. Customers won't have to manage any infrastructure, including integrations with Amazon SageMaker ML features like Experiments for testing different models and Pipelines for managing FMs at scale.\n",
      "Stop reason: end_turn\n",
      "Stop sequence: None\n",
      "Output tokens: 195\n"
     ]
    }
   ],
   "source": [
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\", accept=accept, contentType=contentType)\n",
    "for event in response.get(\"body\"):\n",
    "    chunk = json.loads(event[\"chunk\"][\"bytes\"])\n",
    "\n",
    "    if chunk['type'] == 'message_delta':\n",
    "        print(f\"\\nStop reason: {chunk['delta']['stop_reason']}\")\n",
    "        print(f\"Stop sequence: {chunk['delta']['stop_sequence']}\")\n",
    "        print(f\"Output tokens: {chunk['usage']['output_tokens']}\")\n",
    "\n",
    "    if chunk['type'] == 'content_block_delta':\n",
    "        if chunk['delta']['type'] == 'text_delta':\n",
    "            print(chunk['delta']['text'], end=\"\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8ee83",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have now experimented with using `boto3` SDK which provides a vanilla exposure to Amazon Bedrock API. Using this API you have seen the use case of generating a summary of AWS news about Amazon Bedrock in 2 different ways: entire output and streaming output generation.\n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different models available through Amazon Bedrock such as Amazon Titan and AI21 Labs Jurassic models.\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
